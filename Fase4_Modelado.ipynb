{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b329a2e8",
   "metadata": {},
   "source": [
    "# Tarea 6: La falla del nodo 214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "410dfb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy shape: (2000, 14)\n",
      "Agro shape: (2000, 14)\n",
      "Index(['Ener_1', 'Ener_2', 'Ener_3', 'Ener_4', 'Ener_5', 'Ener_6', 'Ener_7',\n",
      "       'Ener_8', 'Ener_9', 'Ener_10', 'Latitude', 'Longitude', 'Source_Node',\n",
      "       'Target_Node'],\n",
      "      dtype='object')\n",
      "Index(['Agro_1', 'Agro_2', 'Agro_3', 'Agro_4', 'Agro_5', 'Agro_6', 'Agro_7',\n",
      "       'Agro_8', 'Agro_9', 'Agro_10', 'Latitude', 'Longitude', 'Source_Node',\n",
      "       'Target_Node'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "\n",
    "PATHS = {\n",
    "    \"energy_csv\": \"data/ener_clean.csv\",   \n",
    "    \"agro_csv\": \"data/agro_clean.csv\",     \n",
    "}\n",
    "\n",
    "dfE = pd.read_csv(PATHS[\"energy_csv\"])\n",
    "dfA = pd.read_csv(PATHS[\"agro_csv\"])\n",
    "\n",
    "print(\"Energy shape:\", dfE.shape)\n",
    "print(\"Agro shape:\", dfA.shape)\n",
    "print(dfE.columns)\n",
    "print(dfA.columns)\n",
    "\n",
    "def ensure_sorted_by_time(df: pd.DataFrame, time_col_candidates=None):\n",
    "    \"\"\"\n",
    "    Intenta ordenar por una columna temporal si existe.\n",
    "    Si no existe, deja el orden como está (asume que ya está ordenado).\n",
    "    \"\"\"\n",
    "    if time_col_candidates is None:\n",
    "        time_col_candidates = [\"timestamp\", \"date\", \"datetime\", \"time\", \"Fecha\", \"fecha\"]\n",
    "\n",
    "    for c in time_col_candidates:\n",
    "        if c in df.columns:\n",
    "            df = df.copy()\n",
    "            df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "            df = df.sort_values(c)\n",
    "            return df\n",
    "    return df\n",
    "\n",
    "\n",
    "def adf_test(series: pd.Series, name=\"series\"):\n",
    "    \"\"\"\n",
    "    ADF test con impresión clara.\n",
    "    \"\"\"\n",
    "    s = series.dropna()\n",
    "    if len(s) < 20:\n",
    "        return {\"name\": name, \"ok\": False, \"msg\": \"Muy pocos datos para ADF.\"}\n",
    "\n",
    "    stat, pval, usedlag, nobs, crit, icbest = adfuller(s, autolag=\"AIC\")\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"ok\": True,\n",
    "        \"adf_stat\": stat,\n",
    "        \"pvalue\": pval,\n",
    "        \"usedlag\": usedlag,\n",
    "        \"nobs\": nobs,\n",
    "        \"crit\": crit,\n",
    "        \"stationary_5pct\": (pval < 0.05),\n",
    "    }\n",
    "\n",
    "\n",
    "def build_directed_graph_from_edges(df: pd.DataFrame, source_col=\"Source_Node\", target_col=\"Target_Node\"):\n",
    "    \"\"\"\n",
    "    Construye grafo dirigido desde columnas Source_Node y Target_Node.\n",
    "    Si hay repetidos, lo maneja agregando peso por conteo.\n",
    "    \"\"\"\n",
    "    edges = df[[source_col, target_col]].dropna().copy()\n",
    "    # Conteo de aristas repetidas como weight\n",
    "    edge_counts = edges.value_counts().reset_index(name=\"weight\")\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in edge_counts.iterrows():\n",
    "        u = row[source_col]\n",
    "        v = row[target_col]\n",
    "        w = row[\"weight\"]\n",
    "        G.add_edge(u, v, weight=float(w))\n",
    "    return G\n",
    "\n",
    "\n",
    "def safe_granger(df2: pd.DataFrame, maxlag=4, verbose=True):\n",
    "    \"\"\"\n",
    "    Ejecuta Granger con manejo de errores.\n",
    "    df2 debe tener dos columnas en orden [y, x] donde:\n",
    "      - pregunta: \"x causa y?\"\n",
    "      - grangercausalitytests evalúa si x ayuda a predecir y (primera col).\n",
    "    \"\"\"\n",
    "    df2 = df2.dropna()\n",
    "    if len(df2) < (maxlag + 5):\n",
    "        raise ValueError(\"Muy pocos datos para Granger con ese maxlag.\")\n",
    "\n",
    "    results = grangercausalitytests(df2, maxlag=maxlag, verbose=verbose)\n",
    "\n",
    "    # Resumen: tomar p-values del test ssr_ftest por lag\n",
    "    summary = []\n",
    "    for lag in range(1, maxlag + 1):\n",
    "        pval = results[lag][0][\"ssr_ftest\"][1]\n",
    "        summary.append({\"lag\": lag, \"pvalue_ssr_ftest\": pval})\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "def fit_arimax(endog: pd.Series, exog: pd.DataFrame, order=(1,0,1), enforce_stationarity=False, enforce_invertibility=False):\n",
    "    \"\"\"\n",
    "    Ajusta SARIMAX como ARIMAX (sin estacionalidad).\n",
    "    \"\"\"\n",
    "    endog = endog.astype(float)\n",
    "    exog = exog.astype(float)\n",
    "\n",
    "    model = SARIMAX(\n",
    "        endog=endog,\n",
    "        exog=exog,\n",
    "        order=order,\n",
    "        enforce_stationarity=enforce_stationarity,\n",
    "        enforce_invertibility=enforce_invertibility\n",
    "    )\n",
    "    res = model.fit(disp=False)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56741bb",
   "metadata": {},
   "source": [
    "### P1: Causalidad y Redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0852991c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GRAFO ---\n",
      "Nodes: 70 Edges: 865\n",
      "Bottleneck node (max betweenness): 119 | betweenness: 0.0\n",
      "\n",
      "--- P1: GRANGER (Ener_10 -> Ener_9) ---\n",
      "   lag  pvalue_ssr_ftest\n",
      "0    1          0.302454\n",
      "1    2          0.342283\n",
      "2    3          0.430454\n",
      "3    4          0.019318\n",
      "✅ Hay evidencia de causalidad de Granger: Ener_10 ayuda a predecir Ener_9 (en al menos un lag).\n",
      "\n",
      "--- IMPACTO SIMULADO: remover bottleneck ---\n",
      "Strongly connected components BEFORE: 70\n",
      "Strongly connected components AFTER : 69\n",
      "➡️ Si sube mucho después de remover, la red queda más fragmentada (más riesgo de interrupciones).\n"
     ]
    }
   ],
   "source": [
    "# Ordenar por tiempo si aplica\n",
    "dfE = ensure_sorted_by_time(dfE)\n",
    "\n",
    "# Grafo dirigido y centralidades\n",
    "G = build_directed_graph_from_edges(dfE, \"Source_Node\", \"Target_Node\")\n",
    "\n",
    "deg_centrality = nx.degree_centrality(G)  \n",
    "bet_centrality = nx.betweenness_centrality(G, normalized=True, weight=None)  \n",
    "\n",
    "# Nodo cuello de botella:\n",
    "bottleneck_node = max(bet_centrality, key=bet_centrality.get)\n",
    "print(\"\\n--- GRAFO ---\")\n",
    "print(\"Nodes:\", G.number_of_nodes(), \"Edges:\", G.number_of_edges())\n",
    "print(\"Bottleneck node (max betweenness):\", bottleneck_node, \"| betweenness:\", bet_centrality[bottleneck_node])\n",
    "\n",
    "# Granger: Factor de Potencia (Ener_10) -> Voltaje (Ener_9)\n",
    "print(\"\\n--- P1: GRANGER (Ener_10 -> Ener_9) ---\")\n",
    "granger_df = dfE[[\"Ener_9\", \"Ener_10\"]].copy()\n",
    "granger_df = granger_df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Ejecuta test\n",
    "granger_summary = safe_granger(granger_df[[\"Ener_9\", \"Ener_10\"]], maxlag=4, verbose=False)\n",
    "print(granger_summary)\n",
    "\n",
    "# Interpretación simple:\n",
    "if (granger_summary[\"pvalue_ssr_ftest\"] < 0.05).any():\n",
    "    print(\"✅ Hay evidencia de causalidad de Granger: Ener_10 ayuda a predecir Ener_9 (en al menos un lag).\")\n",
    "else:\n",
    "    print(\"❌ No hay evidencia suficiente de Granger (p>=0.05 en todos los lags).\")\n",
    "\n",
    "# Cómo afectaría un fallo del nodo con mayor betweenness:\n",
    "print(\"\\n--- IMPACTO SIMULADO: remover bottleneck ---\")\n",
    "G_removed = G.copy()\n",
    "G_removed.remove_node(bottleneck_node)\n",
    "\n",
    "# Componentes fuertemente conexas (en digrafo)\n",
    "scc_before = nx.number_strongly_connected_components(G)\n",
    "scc_after = nx.number_strongly_connected_components(G_removed)\n",
    "\n",
    "print(\"Strongly connected components BEFORE:\", scc_before)\n",
    "print(\"Strongly connected components AFTER :\", scc_after)\n",
    "print(\"➡️ Si sube mucho después de remover, la red queda más fragmentada (más riesgo de interrupciones).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc61b7cd",
   "metadata": {},
   "source": [
    "### P2: Optimización Geo-Agrónoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810fd5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- P2: GEO-AGRO ---\n",
      "NDVI threshold (10%): 0.7811757380105776\n",
      "Low NDVI count: 200\n",
      "Proporción en alta pendiente: 0.315\n",
      "Proporción en alta varianza de viento: 0.27\n",
      "\n",
      "RECOMENDACIÓN P2: No hay evidencia fuerte de que bajo NDVI coincida masivamente con alta pendiente/varianza de viento: recomienda validar microzonas y priorizar inversión donde sí coincidan condiciones de estrés.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- P2: GEO-AGRO ---\")\n",
    "dfA = ensure_sorted_by_time(dfA)\n",
    "\n",
    "# Suavizado simple para \"filtrar ruido GPS\" (rolling mean)\n",
    "# Ajusta ventana según densidad: 10 es un buen inicio.\n",
    "gps_window = 10\n",
    "dfA[\"Latitude_f\"]  = dfA[\"Latitude\"].rolling(gps_window, min_periods=1).mean()\n",
    "dfA[\"Longitude_f\"] = dfA[\"Longitude\"].rolling(gps_window, min_periods=1).mean()\n",
    "\n",
    "# (B) \"Pendiente\" proxy sin DEM:\n",
    "# Usamos magnitud del gradiente espacial (aprox) como indicador de cambio brusco del terreno/relieve\n",
    "# Nota: en un trabajo real usarías DEM (SRTM, etc.), pero aquí el reto dice \"asuma relación...\"\n",
    "dlat = dfA[\"Latitude_f\"].diff()\n",
    "dlon = dfA[\"Longitude_f\"].diff()\n",
    "dfA[\"slope_proxy\"] = np.sqrt(dlat**2 + dlon**2).fillna(0)\n",
    "\n",
    "# (C) Varianza del viento (Agro_10) en ventana móvil\n",
    "wind_window = 50\n",
    "dfA[\"wind_var\"] = dfA[\"Agro_10\"].rolling(wind_window, min_periods=10).var()\n",
    "\n",
    "# (D) Identificar sensores de menor NDVI (Agro_5)\n",
    "# Regla práctica: bottom 10% como \"bajo NDVI\"\n",
    "ndvi = dfA[\"Agro_5\"].replace([np.inf, -np.inf], np.nan)\n",
    "threshold_ndvi = ndvi.quantile(0.10)\n",
    "\n",
    "low_ndvi = dfA[dfA[\"Agro_5\"] <= threshold_ndvi].copy()\n",
    "\n",
    "# (E) Validar si caen en zona de alta pendiente y alta varianza de viento\n",
    "slope_thr = dfA[\"slope_proxy\"].quantile(0.75)\n",
    "wind_thr  = dfA[\"wind_var\"].quantile(0.75)\n",
    "\n",
    "low_ndvi[\"high_slope\"] = low_ndvi[\"slope_proxy\"] >= slope_thr\n",
    "low_ndvi[\"high_windvar\"] = low_ndvi[\"wind_var\"] >= wind_thr\n",
    "\n",
    "print(\"NDVI threshold (10%):\", threshold_ndvi)\n",
    "print(\"Low NDVI count:\", len(low_ndvi))\n",
    "print(\"Proporción en alta pendiente:\", low_ndvi[\"high_slope\"].mean())\n",
    "print(\"Proporción en alta varianza de viento:\", low_ndvi[\"high_windvar\"].mean())\n",
    "\n",
    "# (F) Recomendación automática (texto base)\n",
    "recommendation = []\n",
    "if low_ndvi[\"high_slope\"].mean() > 0.5 and low_ndvi[\"high_windvar\"].mean() > 0.5:\n",
    "    recommendation.append(\n",
    "        \"Los sensores de bajo NDVI se concentran en zonas con alta pendiente y alta varianza de viento: \"\n",
    "        \"recomienda inversión en infraestructura hídrica (riego por goteo, micro-reservorios) + rompevientos.\"\n",
    "    )\n",
    "else:\n",
    "    recommendation.append(\n",
    "        \"No hay evidencia fuerte de que bajo NDVI coincida masivamente con alta pendiente/varianza de viento: \"\n",
    "        \"recomienda validar microzonas y priorizar inversión donde sí coincidan condiciones de estrés.\"\n",
    "    )\n",
    "print(\"\\nRECOMENDACIÓN P2:\", recommendation[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f64ea",
   "metadata": {},
   "source": [
    "### P3: Analítica Predictiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32a770d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Ener_1: {'name': 'Ener_1', 'ok': True, 'adf_stat': -1.866891087440951, 'pvalue': 0.3477932313370453, 'usedlag': 26, 'nobs': 1973, 'crit': {'1%': -3.4336687168076714, '5%': -2.863006019389988, '10%': -2.567550447906854}, 'stationary_5pct': False}\n",
      "AIC sin centralidad: 8749.99211736723\n",
      "AIC con centralidad: 8751.992117367226\n",
      "❌ No mejora el AIC al incluir centralidad (con este order).\n",
      "\n",
      "--- COEFICIENTES MODELO SIN CENTRALIDAD ---\n",
      "Ener_3   -0.000680\n",
      "ar.L1    -0.054475\n",
      "ma.L1    -0.762763\n",
      "sigma2    4.661078\n",
      "dtype: float64\n",
      "\n",
      "--- COEFICIENTES MODELO CON CENTRALIDAD ---\n",
      "Ener_3       -0.000680\n",
      "centrality    0.000000\n",
      "ar.L1        -0.054475\n",
      "ma.L1        -0.762763\n",
      "sigma2        4.661078\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# (A) Construir exógenas: Temperatura (Ener_3) y centralidad del Source_Node\n",
    "# Centralidad: aquí usamos betweenness (puedes cambiar a degree si quieres)\n",
    "dfE[\"centrality\"] = dfE[\"Source_Node\"].map(bet_centrality)\n",
    "\n",
    "# (B) Preparar series\n",
    "endog_raw = dfE[\"Ener_1\"].replace([np.inf, -np.inf], np.nan)\n",
    "exog_base = dfE[[\"Ener_3\"]].replace([np.inf, -np.inf], np.nan)\n",
    "exog_plus = dfE[[\"Ener_3\", \"centrality\"]].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# (C) Estacionariedad: si no es estacionaria, diferenciar\n",
    "adf_endog = adf_test(endog_raw, \"Ener_1\")\n",
    "print(\"ADF Ener_1:\", adf_endog)\n",
    "\n",
    "if adf_endog.get(\"stationary_5pct\", False):\n",
    "    endog = endog_raw\n",
    "    exog1 = exog_base\n",
    "    exog2 = exog_plus\n",
    "else:\n",
    "    endog = endog_raw.diff()\n",
    "    exog1 = exog_base.iloc[1:].copy()\n",
    "    exog2 = exog_plus.iloc[1:].copy()\n",
    "\n",
    "# Alinear NaNs\n",
    "df_model1 = pd.concat([endog, exog1], axis=1).dropna()\n",
    "df_model2 = pd.concat([endog, exog2], axis=1).dropna()\n",
    "\n",
    "endog1 = df_model1.iloc[:, 0]\n",
    "X1 = df_model1.iloc[:, 1:]\n",
    "\n",
    "endog2 = df_model2.iloc[:, 0]\n",
    "X2 = df_model2.iloc[:, 1:]\n",
    "\n",
    "# (D) Ajuste ARIMAX (elige un order base, puedes tunear con grid si quieres)\n",
    "order = (1, 0, 1)\n",
    "\n",
    "res1 = fit_arimax(endog1, X1, order=order)\n",
    "res2 = fit_arimax(endog2, X2, order=order)\n",
    "\n",
    "print(\"AIC sin centralidad:\", res1.aic)\n",
    "print(\"AIC con centralidad:\", res2.aic)\n",
    "\n",
    "if res2.aic < res1.aic:\n",
    "    print(\"✅ Incluir centralidad mejora el AIC (mejor ajuste).\")\n",
    "else:\n",
    "    print(\"❌ No mejora el AIC al incluir centralidad (con este order).\")\n",
    "\n",
    "# (E) Mostrar coeficientes\n",
    "print(\"\\n--- COEFICIENTES MODELO SIN CENTRALIDAD ---\")\n",
    "print(res1.params)\n",
    "\n",
    "print(\"\\n--- COEFICIENTES MODELO CON CENTRALIDAD ---\")\n",
    "print(res2.params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6094d9",
   "metadata": {},
   "source": [
    "### Informe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "930613bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== RESUMEN PARA INFORME ====================\n",
      "bottleneck_node : 119\n",
      "bottleneck_betweenness : 0.0\n",
      "granger_summary :    lag  pvalue_ssr_ftest\n",
      "0    1          0.302454\n",
      "1    2          0.342283\n",
      "2    3          0.430454\n",
      "3    4          0.019318\n",
      "scc_before : 70\n",
      "scc_after : 69\n",
      "ndvi_threshold_10pct : 0.7811757380105776\n",
      "low_ndvi_count : 200\n",
      "low_ndvi_high_slope_ratio : 0.315\n",
      "low_ndvi_high_windvar_ratio : 0.27\n",
      "arimax_aic_no_centrality : 8749.99211736723\n",
      "arimax_aic_with_centrality : 8751.992117367226\n",
      "p2_recommendation : No hay evidencia fuerte de que bajo NDVI coincida masivamente con alta pendiente/varianza de viento: recomienda validar microzonas y priorizar inversión donde sí coincidan condiciones de estrés.\n"
     ]
    }
   ],
   "source": [
    "outputs = {\n",
    "    \"bottleneck_node\": bottleneck_node,\n",
    "    \"bottleneck_betweenness\": float(bet_centrality[bottleneck_node]),\n",
    "    \"granger_summary\": granger_summary,\n",
    "    \"scc_before\": int(scc_before),\n",
    "    \"scc_after\": int(scc_after),\n",
    "    \"ndvi_threshold_10pct\": float(threshold_ndvi) if pd.notna(threshold_ndvi) else None,\n",
    "    \"low_ndvi_count\": int(len(low_ndvi)),\n",
    "    \"low_ndvi_high_slope_ratio\": float(low_ndvi[\"high_slope\"].mean()) if len(low_ndvi) else None,\n",
    "    \"low_ndvi_high_windvar_ratio\": float(low_ndvi[\"high_windvar\"].mean()) if len(low_ndvi) else None,\n",
    "    \"arimax_aic_no_centrality\": float(res1.aic),\n",
    "    \"arimax_aic_with_centrality\": float(res2.aic),\n",
    "    \"p2_recommendation\": recommendation[0],\n",
    "}\n",
    "\n",
    "print(\"\\n==================== RESUMEN PARA INFORME ====================\")\n",
    "for k, v in outputs.items():\n",
    "    print(k, \":\", v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
